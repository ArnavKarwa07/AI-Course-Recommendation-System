{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a317b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mysql.connector\n",
    "import decimal\n",
    "import datetime\n",
    "from typing import TypedDict, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "import time\n",
    "import httpx\n",
    "import re\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f765b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Groq LLM\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", api_key=os.getenv(\"GROQ_API_KEY\"), http_client=httpx.Client(verify=False))\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Database connection management\n",
    "def get_db_connection():\n",
    "    \"\"\"Get a fresh database connection\"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=os.getenv(\"DB_HOST\"),\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            password=os.getenv(\"DB_PASSWORD\"),\n",
    "            database=os.getenv(\"DB_NAME\"),\n",
    "            port=int(os.getenv(\"DB_PORT\", \"3306\")),\n",
    "            autocommit=True,\n",
    "            connection_timeout=30,\n",
    "            pool_reset_session=True\n",
    "        )\n",
    "        return connection\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection error: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_db_cursor():\n",
    "    \"\"\"Get a fresh database cursor\"\"\"\n",
    "    connection = get_db_connection()\n",
    "    return connection, connection.cursor(dictionary=True)\n",
    "\n",
    "print(\"Database connection functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6cac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph state\n",
    "class AgentState(TypedDict):\n",
    "    emp_id: int\n",
    "    goal: str\n",
    "    retry_count: int = 0\n",
    "    user_data: Dict[str, Any]\n",
    "    llm_analysis: str\n",
    "    output: str\n",
    "    is_valid: bool\n",
    "    validation_summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af79d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize data for JSON (handles date and decimal)\n",
    "def serialize(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: serialize(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize(v) for v in obj]\n",
    "    elif isinstance(obj, (datetime.date, datetime.datetime)):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, decimal.Decimal):\n",
    "        return float(obj)\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract JSON block from text\n",
    "def extract_json_block(text):\n",
    "    matches = re.findall(r\"```json(.*?)```\", text, re.DOTALL)\n",
    "    if matches:\n",
    "        try:\n",
    "            return json.loads(matches[0].strip())\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6674a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Collect user data\n",
    "def collect_user_data(state: AgentState) -> AgentState:\n",
    "    emp_id = state[\"emp_id\"]\n",
    "    \n",
    "    # Get fresh database connection\n",
    "    db, cursor = get_db_cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT * FROM m_emp WHERE emp_id = %s\", (emp_id,))\n",
    "        emp = cursor.fetchone()\n",
    "\n",
    "        cursor.execute(\"SELECT * FROM m_roles WHERE role_id = %s\", (emp[\"role_id\"],))\n",
    "        emp[\"role_details\"] = cursor.fetchone()\n",
    "\n",
    "        cursor.execute(\"SELECT * FROM t_emp_kpi WHERE emp_id = %s\", (emp_id,))\n",
    "        emp[\"kpis\"] = cursor.fetchall()\n",
    "\n",
    "        cursor.execute(\"SELECT * FROM t_emp_projects WHERE emp_id = %s\", (emp_id,))\n",
    "        emp[\"projects\"] = cursor.fetchall()\n",
    "\n",
    "        cursor.execute(\"SELECT * FROM t_course_completion WHERE emp_id = %s\", (emp_id,))\n",
    "        emp[\"courses\"] = cursor.fetchall()\n",
    "\n",
    "        state[\"user_data\"] = emp\n",
    "        print(\"User data collected:\", emp)\n",
    "        return state\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad519531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Analyze user\n",
    "def analyze_user_data(state: AgentState) -> AgentState:\n",
    "    emp = serialize(state[\"user_data\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following employee using:\n",
    "- General info\n",
    "- Skills\n",
    "- Completed courses\n",
    "- Completed projects\n",
    "- Role expectations\n",
    "- KPIs\n",
    "\n",
    "Return JSON with:\n",
    "1. behavior_traits\n",
    "2. learning_preferences\n",
    "3. skill_gaps\n",
    "\n",
    "Employee:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\"\"\"\n",
    "    result = llm.invoke([HumanMessage(content=prompt)])\n",
    "    state[\"llm_analysis\"] = result.content\n",
    "    print(\"LLM Analysis:\", state[\"llm_analysis\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Generate output\n",
    "def generate_output(state: AgentState) -> AgentState:\n",
    "    emp = serialize(state[\"user_data\"])\n",
    "    analysis = state[\"llm_analysis\"]\n",
    "    goal = state[\"goal\"]\n",
    "\n",
    "    # Get fresh database connection\n",
    "    db, cursor = get_db_cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT * FROM m_courses\")\n",
    "        courses = cursor.fetchall()\n",
    "\n",
    "        if goal == \"roadmap\":\n",
    "            prompt = f\"\"\"\n",
    "Using the employee profile and analysis below, generate a skill development roadmap using the available courses.\n",
    "\n",
    "Analysis:\n",
    "{analysis}\n",
    "\n",
    "Employee:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\n",
    "Courses:\n",
    "{json.dumps(serialize(courses), indent=2)}\n",
    "\n",
    "Return JSON:\n",
    "[\n",
    "  {{\n",
    "    \"c_name\": \"...\",\n",
    "    \"desc\": \"...\",\n",
    "    \"start_date\": \"YYYY-MM-DD\",\n",
    "    \"duration\": months,\n",
    "    \"end_date\": \"YYYY-MM-DD\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "Based on the employee profile and analysis, recommend a list of best-fit courses to bridge skill gaps.\n",
    "\n",
    "Analysis:\n",
    "{analysis}\n",
    "\n",
    "Employee:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\n",
    "Courses:\n",
    "{json.dumps(serialize(courses), indent=2)}\n",
    "\n",
    "Return JSON:\n",
    "[\n",
    "  {{\n",
    "    \"c_name\": \"...\",\n",
    "    \"desc\": \"...\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "        result = llm.invoke([HumanMessage(content=prompt)])\n",
    "        state[\"output\"] = result.content\n",
    "        print(\"Generated Output:\", state[\"output\"])\n",
    "        return state\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Combined Analyze and Generate\n",
    "def analyze_and_generate(state: AgentState) -> AgentState:\n",
    "    emp = serialize(state[\"user_data\"])\n",
    "    goal = state[\"goal\"]\n",
    "\n",
    "    # Get fresh database connection\n",
    "    db, cursor = get_db_cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT * FROM m_courses\")\n",
    "        courses = cursor.fetchall()\n",
    "\n",
    "        if goal == \"roadmap\":\n",
    "            prompt = f\"\"\"\n",
    "Role:\n",
    "You are an expert HR Learning & Development specialist responsible for creating personalized skill development roadmaps for employees.\n",
    "\n",
    "Action:\n",
    "Analyze the given employee profile and create a comprehensive skill development roadmap using the available courses. First, conduct a thorough analysis of the employee's current state, then generate a strategic learning pathway.\n",
    "\n",
    "Analysis Steps:\n",
    "1. Evaluate general info, skills, completed courses, completed projects, role expectations, and KPIs\n",
    "2. Identify behavior_traits, learning_preferences, and skill_gaps\n",
    "3. Map skill gaps to available courses\n",
    "4. Create a timeline-based roadmap with logical progression\n",
    "\n",
    "Guardrails/Guidelines:\n",
    "- Only recommend courses from the provided course catalog\n",
    "- Ensure logical skill progression (foundational before advanced)\n",
    "- Consider the employee's current role and career trajectory\n",
    "- Account for realistic timeframes and workload\n",
    "- Prioritize skill gaps that align with role expectations and KPIs\n",
    "- Include start dates, duration, and end dates for each course\n",
    "\n",
    "Output format:\n",
    "Return only a JSON array with the following structure:\n",
    "[\n",
    "  {{\n",
    "    \"c_name\": \"Course Name\",\n",
    "    \"desc\": \"Brief description of why this course fits the employee\",\n",
    "    \"start_date\": \"YYYY-MM-DD\",\n",
    "    \"duration\": number_of_months,\n",
    "    \"end_date\": \"YYYY-MM-DD\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "Employee Profile:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\n",
    "Available Courses:\n",
    "{json.dumps(serialize(courses), indent=2)}\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "Role:\n",
    "You are an expert HR Learning & Development specialist responsible for recommending the most suitable courses for employees based on their profiles and skill gaps.\n",
    "\n",
    "Action:\n",
    "Analyze the given employee profile and recommend the best-fit courses to bridge identified skill gaps. First, conduct a comprehensive analysis of the employee's current state, then provide targeted course recommendations.\n",
    "\n",
    "Analysis Steps:\n",
    "1. Evaluate general info, skills, completed courses, completed projects, role expectations, and KPIs\n",
    "2. Identify behavior_traits, learning_preferences, and skill_gaps\n",
    "3. Match skill gaps with the most relevant available courses\n",
    "4. Prioritize courses based on impact and relevance\n",
    "\n",
    "Guardrails/Guidelines:\n",
    "- Only recommend courses from the provided course catalog\n",
    "- Focus on courses that directly address identified skill gaps\n",
    "- Consider the employee's learning preferences and past course completions\n",
    "- Prioritize courses that align with role expectations and KPI improvements\n",
    "- Provide clear rationale for each course recommendation\n",
    "- Limit recommendations to the most impactful courses (typically 3-7 courses)\n",
    "\n",
    "Output format:\n",
    "Return only a JSON array with the following structure:\n",
    "[\n",
    "  {{\n",
    "    \"c_name\": \"Course Name\",\n",
    "    \"desc\": \"Brief description of why this course fits the employee and addresses specific skill gaps\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "Employee Profile:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\n",
    "Available Courses:\n",
    "{json.dumps(serialize(courses), indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "        result = llm.invoke([HumanMessage(content=prompt)])\n",
    "        state[\"output\"] = result.content\n",
    "        print(\"Combined Analysis and Generated Output:\", state[\"output\"])\n",
    "        return state\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf02fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Validate output\n",
    "def validate_output(state: AgentState) -> AgentState:\n",
    "    emp = serialize(state[\"user_data\"])\n",
    "    output = state[\"output\"]\n",
    "    goal = state[\"goal\"]\n",
    "    \n",
    "    # Get fresh database connection\n",
    "    db, cursor = get_db_cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(\"SELECT * FROM m_courses\")\n",
    "        courses = cursor.fetchall()\n",
    "\n",
    "#       prompt = f\"\"\"\n",
    "# You are validating the following {goal} output.\n",
    "# Courses:\n",
    "# {courses}\n",
    "\n",
    "# Analysis:\n",
    "# {analysis}\n",
    "\n",
    "# Employee:\n",
    "# {json.dumps(emp, indent=2)}\n",
    "\n",
    "# Output:\n",
    "# {output}\n",
    "\n",
    "# Return JSON:\n",
    "# {{\n",
    "#   \"valid\": true or false,\n",
    "#   \"reason\": \"...\",\n",
    "# }}\n",
    "# \"\"\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "Role:\n",
    "You are an expert Quality Assurance specialist responsible for validating AI-generated learning recommendations and skill development roadmaps for employees.\n",
    "\n",
    "Action:\n",
    "Validate the following {goal} output by checking its accuracy, relevance, and adherence to guidelines. Evaluate whether the recommendations are appropriate for the given employee profile and utilize only the available courses from the catalog.\n",
    "\n",
    "Validation Steps:\n",
    "1. Verify all recommended courses exist in the provided course catalog\n",
    "2. Check if recommendations align with the employee's skill gaps and role requirements\n",
    "3. Ensure the output format matches expected JSON structure\n",
    "4. Validate that course selections are logical and progressive (for roadmaps)\n",
    "5. Confirm recommendations consider the employee's background and completed courses\n",
    "\n",
    "Guardrails/Guidelines:\n",
    "- All recommended courses must exist in the course catalog\n",
    "- Recommendations should directly address identified skill gaps\n",
    "- Output must be in proper JSON format\n",
    "- For roadmaps: dates should be realistic and sequential\n",
    "- Recommendations should align with employee's role and KPIs\n",
    "- Avoid recommending courses the employee has already completed\n",
    "\n",
    "Output format:\n",
    "Return only a JSON object with the following structure:\n",
    "{{\n",
    "  \"valid\": true or false,\n",
    "  \"reason\": \"Detailed explanation of validation result, including specific issues if invalid\"\n",
    "}}\n",
    "\n",
    "Available Courses:\n",
    "{courses}\n",
    "\n",
    "Employee Profile:\n",
    "{json.dumps(emp, indent=2)}\n",
    "\n",
    "Generated {goal} Output to Validate:\n",
    "{output}\n",
    "\"\"\"\n",
    "        result = llm.invoke([HumanMessage(content=prompt)])\n",
    "        try:\n",
    "            check = extract_json_block(result.content)\n",
    "            print(\"Validation Check:\", check)\n",
    "            state[\"is_valid\"] = check[\"valid\"]\n",
    "        except:\n",
    "            state[\"is_valid\"] = True  # Assume valid if parsing fails\n",
    "\n",
    "        state[\"validation_summary\"] = result.content\n",
    "        print(\"Validation Summary:\", state[\"validation_summary\"])\n",
    "        print(\"Validation Result:\", state[\"is_valid\"])\n",
    "        return state\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Final output\n",
    "def final_output(state: AgentState) -> AgentState:\n",
    "    extracted_json = extract_json_block(state[\"output\"])\n",
    "    print(f\"\\nâœ… FINAL {state['goal'].upper()}\")\n",
    "    if extracted_json:\n",
    "        print(extracted_json)\n",
    "    else:\n",
    "        print(\"âŒ Failed to extract JSON from output.\")\n",
    "        print(state[\"output\"])\n",
    "    return state\n",
    "\n",
    "def fallback_output(state: AgentState) -> AgentState:\n",
    "    print(\"\\nâŒ Output failed validation even after retry.\")\n",
    "    print(\"ðŸ” Please review manually:\")\n",
    "    extracted_json = extract_json_block(state[\"output\"])\n",
    "    if extracted_json:\n",
    "        print(extracted_json)\n",
    "    else:\n",
    "        print(\"âŒ Failed to extract JSON from output.\")\n",
    "        print(state[\"output\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74935ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph setup\n",
    "def build_graph():\n",
    "    builder = StateGraph(AgentState)\n",
    "\n",
    "    builder.add_node(\"Collect\", collect_user_data)\n",
    "    builder.add_node(\"Analyze\", analyze_user_data)\n",
    "    builder.add_node(\"Generate\", generate_output)\n",
    "    builder.add_node(\"Validate\", validate_output)\n",
    "    builder.add_node(\"FinalOutput\", final_output)\n",
    "    builder.add_node(\"FallbackOutput\", fallback_output)\n",
    "\n",
    "    builder.set_entry_point(\"Collect\")\n",
    "    builder.add_edge(\"Collect\", \"Analyze\")\n",
    "    builder.add_edge(\"Analyze\", \"Generate\")\n",
    "    builder.add_edge(\"Generate\", \"Validate\")\n",
    "    # builder.add_edge(\"Generate\", \"FinalOutput\")\n",
    "\n",
    "    def output_selector(state: AgentState) -> str:\n",
    "        if state[\"is_valid\"]:\n",
    "            return \"FinalOutput\"\n",
    "        elif state[\"retry_count\"] == 0:\n",
    "            state[\"retry_count\"] = 1\n",
    "            return \"Analyze\"\n",
    "        else:\n",
    "            return \"FallbackOutput\"\n",
    "\n",
    "    builder.add_conditional_edges(\"Validate\", output_selector, {\n",
    "        \"FinalOutput\": \"FinalOutput\",\n",
    "        \"Analyze\": \"Analyze\",\n",
    "        \"FallbackOutput\": \"FallbackOutput\"\n",
    "    })\n",
    "    builder.add_edge(\"FinalOutput\", END)\n",
    "    builder.add_edge(\"FallbackOutput\", END)\n",
    "\n",
    "    return builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated LangGraph setup with combined function\n",
    "def build_graph_combined():\n",
    "    builder = StateGraph(AgentState)\n",
    "\n",
    "    builder.add_node(\"Collect\", collect_user_data)\n",
    "    builder.add_node(\"AnalyzeAndGenerate\", analyze_and_generate)\n",
    "    builder.add_node(\"Validate\", validate_output)\n",
    "    builder.add_node(\"FinalOutput\", final_output)\n",
    "    builder.add_node(\"FallbackOutput\", fallback_output)\n",
    "\n",
    "    builder.set_entry_point(\"Collect\")\n",
    "    builder.add_edge(\"Collect\", \"AnalyzeAndGenerate\")\n",
    "    builder.add_edge(\"AnalyzeAndGenerate\", \"Validate\")\n",
    "\n",
    "    def output_selector(state: AgentState) -> str:\n",
    "        if state[\"is_valid\"]:\n",
    "            return \"FinalOutput\"\n",
    "        elif state[\"retry_count\"] == 0:\n",
    "            state[\"retry_count\"] = 1\n",
    "            return \"AnalyzeAndGenerate\"\n",
    "        else:\n",
    "            return \"FallbackOutput\"\n",
    "\n",
    "    builder.add_conditional_edges(\"Validate\", output_selector, {\n",
    "        \"FinalOutput\": \"FinalOutput\",\n",
    "        \"AnalyzeAndGenerate\": \"AnalyzeAndGenerate\",\n",
    "        \"FallbackOutput\": \"FallbackOutput\"\n",
    "    })\n",
    "    builder.add_edge(\"FinalOutput\", END)\n",
    "    builder.add_edge(\"FallbackOutput\", END)\n",
    "\n",
    "    return builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95387d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_id = 120            # Change as needed\n",
    "goal = \"roadmap\"        # Use \"roadmap\" or \"courses\"\n",
    "\n",
    "graph = build_graph_combined()\n",
    "print(graph.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\n",
    "    \"emp_id\": emp_id,\n",
    "    \"goal\": goal,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39368c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(\"\\nFinal Agent State:\")\n",
    "pprint(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
